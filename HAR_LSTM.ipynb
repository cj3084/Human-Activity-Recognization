{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"_Gbf2s7Qr8iX"},"outputs":[],"source":["# Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t4_wnSnBr8if"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2SINm9A0r8ih"},"outputs":[],"source":["# Activities are the class labels\n","# It is a 6 class classification\n","ACTIVITIES = {\n","    0: 'WALKING',\n","    1: 'WALKING_UPSTAIRS',\n","    2: 'WALKING_DOWNSTAIRS',\n","    3: 'SITTING',\n","    4: 'STANDING',\n","    5: 'LAYING',\n","}\n","\n","# Utility function to print the confusion matrix\n","def confusion_matrix(Y_true, Y_pred):\n","    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n","    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n","\n","    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"]},{"cell_type":"markdown","metadata":{"id":"lhsKXwEHr8ii"},"source":["### Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJ5T9Fd7r8il"},"outputs":[],"source":["# Data directory\n","DATADIR = 'UCI_HAR_Dataset'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cTpjnijqr8im"},"outputs":[],"source":["# Raw data signals\n","# Signals are from Accelerometer and Gyroscope\n","# The signals are in x,y,z directions\n","# Sensor signals are filtered to have only body acceleration\n","# excluding the acceleration due to gravity\n","# Triaxial acceleration from the accelerometer is total acceleration\n","SIGNALS = [\n","    \"body_acc_x\",\n","    \"body_acc_y\",\n","    \"body_acc_z\",\n","    \"body_gyro_x\",\n","    \"body_gyro_y\",\n","    \"body_gyro_z\",\n","    \"total_acc_x\",\n","    \"total_acc_y\",\n","    \"total_acc_z\"\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SRSpAp0dr8io"},"outputs":[],"source":["# Utility function to read the data from csv file\n","def _read_csv(filename):\n","    return pd.read_csv(filename, delim_whitespace=True, header=None)\n","\n","# Utility function to load the load\n","def load_signals(subset):\n","    signals_data = []\n","\n","    for signal in SIGNALS:\n","        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n","        signals_data.append(\n","            _read_csv(filename).values\n","        ) \n","\n","    # Transpose is used to change the dimensionality of the output,\n","    # aggregating the signals by combination of sample/timestep.\n","    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n","    return np.transpose(signals_data, (1, 2, 0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vAjjAHpYr8iq"},"outputs":[],"source":["\n","def load_y(subset):\n","    \"\"\"\n","    The objective that we are trying to predict is a integer, from 1 to 6,\n","    that represents a human activity. We return a binary representation of \n","    every sample objective as a 6 bits vector using One Hot Encoding\n","    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n","    \"\"\"\n","    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n","    y = _read_csv(filename)[0]\n","\n","    return pd.get_dummies(y).values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-ZgWpmKr8is"},"outputs":[],"source":["def load_data():\n","    \"\"\"\n","    Obtain the dataset from multiple files.\n","    Returns: X_train, X_test, y_train, y_test\n","    \"\"\"\n","    X_train, X_test = load_signals('train'), load_signals('test')\n","    y_train, y_test = load_y('train'), load_y('test')\n","\n","    return X_train, X_test, y_train, y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u9Qi8rfyr8it"},"outputs":[],"source":["# Importing tensorflow\n","np.random.seed(42)\n","import tensorflow as tf\n","tf.random.set_seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SGRADlB9r8iu"},"outputs":[],"source":["# Configuring a session\n","session_conf = tf.compat.v1.ConfigProto(\n","    intra_op_parallelism_threads=1,\n","    inter_op_parallelism_threads=1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dkvP7yv7r8iv"},"outputs":[],"source":["# Import Keras\n","from keras import backend as K\n","sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","K.set_session(sess)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qIUe82dfr8iw"},"outputs":[],"source":["# Importing libraries\n","from keras.models import Sequential\n","from keras.layers import LSTM\n","from keras.layers.core import Dense, Dropout"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oWIGkd04r8iw"},"outputs":[],"source":["# Initializing parameters\n","epochs = 30\n","batch_size = 16\n","n_hidden = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0I2V7KJr8ix"},"outputs":[],"source":["# Utility function to count the number of classes\n","def _count_classes(y):\n","    return len(set([tuple(category) for category in y]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BIuLw97gr8iy"},"outputs":[],"source":["# Loading the train and test data\n","X_train, X_test, Y_train, Y_test = load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"83R0Epdlr8iy","outputId":"b21c4ab9-7ccf-481e-ccb5-11d5cdc2e3ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["128\n","9\n","7352\n"]}],"source":["timesteps = len(X_train[0])\n","input_dim = len(X_train[0][0])\n","n_classes = _count_classes(Y_train)\n","\n","print(timesteps)\n","print(input_dim)\n","print(len(X_train))"]},{"cell_type":"markdown","metadata":{"id":"MzPVFLmor8i0"},"source":["- Defining the Architecture of LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RARCrLTyr8i1","outputId":"ed8fb825-8f29-44bf-f23a-28b5f8aa7834"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_10 (LSTM)              (None, 128, 32)           5376      \n","                                                                 \n"," dropout_5 (Dropout)         (None, 128, 32)           0         \n","                                                                 \n"," lstm_11 (LSTM)              (None, 32)                8320      \n","                                                                 \n"," dropout_6 (Dropout)         (None, 32)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 6)                 198       \n","                                                                 \n","=================================================================\n","Total params: 13,894\n","Trainable params: 13,894\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# Initiliazing the sequential model\n","model = Sequential()\n","# Configuring the parameters\n","model.add(LSTM(n_hidden,return_sequences=True, input_shape=(timesteps, input_dim)))\n","model.add(Dropout(0.5))\n","model.add(LSTM(n_hidden))\n","# Adding a dropout layer\n","model.add(Dropout(0.7))\n","# Adding a dense output layer with sigmoid activation\n","model.add(Dense(n_classes, activation='sigmoid'))\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y6_uMiwLr8i1"},"outputs":[],"source":["# Compiling the model\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RudGu71sr8i2","outputId":"b26c55ed-0f39-4c75-8095-ea95dc93d6e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","460/460 [==============================] - 74s 148ms/step - loss: 1.1561 - accuracy: 0.5052 - val_loss: 0.8032 - val_accuracy: 0.6454\n","Epoch 2/30\n","460/460 [==============================] - 61s 133ms/step - loss: 0.7939 - accuracy: 0.6504 - val_loss: 0.7129 - val_accuracy: 0.6977\n","Epoch 3/30\n","460/460 [==============================] - 63s 137ms/step - loss: 0.6520 - accuracy: 0.7375 - val_loss: 1.1063 - val_accuracy: 0.6882\n","Epoch 4/30\n","460/460 [==============================] - 58s 125ms/step - loss: 0.5377 - accuracy: 0.8147 - val_loss: 0.5639 - val_accuracy: 0.7930\n","Epoch 5/30\n","460/460 [==============================] - 59s 129ms/step - loss: 0.4891 - accuracy: 0.8245 - val_loss: 0.5163 - val_accuracy: 0.8351\n","Epoch 6/30\n","460/460 [==============================] - 56s 123ms/step - loss: 0.3949 - accuracy: 0.8829 - val_loss: 0.3918 - val_accuracy: 0.8782\n","Epoch 7/30\n","460/460 [==============================] - 57s 123ms/step - loss: 0.3481 - accuracy: 0.9013 - val_loss: 0.5120 - val_accuracy: 0.8429\n","Epoch 8/30\n","460/460 [==============================] - 61s 132ms/step - loss: 0.4293 - accuracy: 0.8604 - val_loss: 0.3699 - val_accuracy: 0.8656\n","Epoch 9/30\n","460/460 [==============================] - 56s 121ms/step - loss: 0.2814 - accuracy: 0.9197 - val_loss: 0.3150 - val_accuracy: 0.8941\n","Epoch 10/30\n","460/460 [==============================] - 59s 128ms/step - loss: 0.2501 - accuracy: 0.9261 - val_loss: 0.3008 - val_accuracy: 0.9033\n","Epoch 11/30\n","460/460 [==============================] - 59s 127ms/step - loss: 0.2208 - accuracy: 0.9331 - val_loss: 0.2994 - val_accuracy: 0.9013\n","Epoch 12/30\n","460/460 [==============================] - 61s 133ms/step - loss: 0.2527 - accuracy: 0.9149 - val_loss: 0.3136 - val_accuracy: 0.8996\n","Epoch 13/30\n","460/460 [==============================] - 60s 131ms/step - loss: 0.2194 - accuracy: 0.9289 - val_loss: 0.4235 - val_accuracy: 0.8731\n","Epoch 14/30\n","460/460 [==============================] - 57s 124ms/step - loss: 0.2072 - accuracy: 0.9294 - val_loss: 0.3431 - val_accuracy: 0.9036\n","Epoch 15/30\n","460/460 [==============================] - 58s 125ms/step - loss: 0.2167 - accuracy: 0.9312 - val_loss: 0.3089 - val_accuracy: 0.9046\n","Epoch 16/30\n","460/460 [==============================] - 61s 132ms/step - loss: 0.1980 - accuracy: 0.9373 - val_loss: 0.2701 - val_accuracy: 0.9175\n","Epoch 17/30\n","460/460 [==============================] - 59s 128ms/step - loss: 0.1876 - accuracy: 0.9406 - val_loss: 0.3668 - val_accuracy: 0.9013\n","Epoch 18/30\n","460/460 [==============================] - 57s 125ms/step - loss: 0.1797 - accuracy: 0.9287 - val_loss: 0.5033 - val_accuracy: 0.8707\n","Epoch 19/30\n","460/460 [==============================] - 59s 128ms/step - loss: 0.2185 - accuracy: 0.9248 - val_loss: 0.5971 - val_accuracy: 0.8629\n","Epoch 20/30\n","460/460 [==============================] - 68s 148ms/step - loss: 0.1904 - accuracy: 0.9289 - val_loss: 0.4364 - val_accuracy: 0.8938\n","Epoch 21/30\n","460/460 [==============================] - 56s 121ms/step - loss: 0.1632 - accuracy: 0.9381 - val_loss: 0.3462 - val_accuracy: 0.9063\n","Epoch 22/30\n","460/460 [==============================] - 52s 112ms/step - loss: 0.1552 - accuracy: 0.9436 - val_loss: 0.3199 - val_accuracy: 0.9091\n","Epoch 23/30\n","460/460 [==============================] - 55s 120ms/step - loss: 0.1443 - accuracy: 0.9459 - val_loss: 0.2913 - val_accuracy: 0.9206\n","Epoch 24/30\n","460/460 [==============================] - 55s 119ms/step - loss: 0.2134 - accuracy: 0.9355 - val_loss: 0.2732 - val_accuracy: 0.9097\n","Epoch 25/30\n","460/460 [==============================] - 53s 115ms/step - loss: 0.1915 - accuracy: 0.9395 - val_loss: 0.3219 - val_accuracy: 0.9104\n","Epoch 26/30\n","460/460 [==============================] - 57s 124ms/step - loss: 0.2079 - accuracy: 0.9363 - val_loss: 0.3421 - val_accuracy: 0.9026\n","Epoch 27/30\n","460/460 [==============================] - 63s 138ms/step - loss: 0.1774 - accuracy: 0.9403 - val_loss: 0.3631 - val_accuracy: 0.9053\n","Epoch 28/30\n","460/460 [==============================] - 61s 133ms/step - loss: 0.1793 - accuracy: 0.9414 - val_loss: 0.3774 - val_accuracy: 0.9091\n","Epoch 29/30\n","460/460 [==============================] - 53s 115ms/step - loss: 0.1712 - accuracy: 0.9418 - val_loss: 0.3411 - val_accuracy: 0.9165\n","Epoch 30/30\n","460/460 [==============================] - 63s 137ms/step - loss: 0.1884 - accuracy: 0.9344 - val_loss: 0.3335 - val_accuracy: 0.9162\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f09cea6d460>"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# Training the model\n","model.fit(X_train,\n","          Y_train,\n","          batch_size=batch_size,\n","          validation_data=(X_test, Y_test),\n","          epochs=epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k6iVgvQyr8i3","outputId":"9c1f432d-4a0c-43cf-d97a-001400014a1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n","True                                                                         \n","LAYING                 537        0         0        0                   0   \n","SITTING                  1      419        47        0                   2   \n","STANDING                 0      118       411        3                   0   \n","WALKING                  0        0         0      470                  21   \n","WALKING_DOWNSTAIRS       0        0         0        1                 419   \n","WALKING_UPSTAIRS         0        1         0       19                   7   \n","\n","Pred                WALKING_UPSTAIRS  \n","True                                  \n","LAYING                             0  \n","SITTING                           22  \n","STANDING                           0  \n","WALKING                            5  \n","WALKING_DOWNSTAIRS                 0  \n","WALKING_UPSTAIRS                 444  \n"]}],"source":["# Confusion Matrix\n","print(confusion_matrix(Y_test, model.predict(X_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L3kSDhaOr8i3","outputId":"ef13415b-03e0-4415-9190-b9502e0c67c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["93/93 [==============================] - 3s 34ms/step - loss: 0.3335 - accuracy: 0.9162\n"]}],"source":["score = model.evaluate(X_test, Y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"keaQ5UG4r8i4","outputId":"dc963fcf-a970-4954-e308-2cb2634e14fb"},"outputs":[{"data":{"text/plain":["[0.3334912955760956, 0.9161859750747681]"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["score"]},{"cell_type":"markdown","metadata":{"id":"eRdGWs1Br8i5"},"source":["- With a simple 2 layer architecture we got 91.62% accuracy and a loss of 0.33\n","- We can further imporve the performace with Hyperparameter tuning"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"name":"HAR_LSTM.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}